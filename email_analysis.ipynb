{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import sys\n",
      "import os\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data\n",
      "f = open(\"acmemails.json\")\n",
      "json_str = f.read()\n",
      "f.close()\n",
      "\n",
      "emails = json.loads(json_str)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Length related stuff\n",
      "lengths = [len(email['message']) for email in emails]\n",
      "emails_by_length = sorted(emails, lambda e1, e2: len(e2['message']) - len(e1['message']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [email['message'] for email in emails]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove common words and tokenize\n",
      "stoplist = set('for a of the and to in - . if i you be : / * this as on is at are an we'.split())\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
      "         for document in documents]\n",
      "\n",
      "# remove words that appear only once\n",
      "all_tokens = sum(texts, [])\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once] for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(texts)\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus)\n",
      "corpus_tfidf = tfidf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=5)\n",
      "corpus_lsi = lsi[corpus_tfidf]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.print_topics(40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['0.098*\"will\" + 0.098*\"your\" + 0.096*\"code@night\" + 0.092*\"up\" + 0.089*\"with\" + 0.088*\"april\" + 0.088*\"have\" + 0.086*\"about\" + 0.085*\"sign\" + 0.085*\"that\"',\n",
        " '0.500*\"edward\" + 0.140*\"study\" + 0.124*\"tech\" + 0.112*\"code@night\" + 0.109*\"there!\" + 0.104*\"break\" + -0.103*\"classes\" + 0.102*\"bloomberg\" + 0.098*\"pizza\" + 0.098*\"interview\"',\n",
        " '-0.607*\"edward\" + -0.161*\"chair\" + 0.140*\"code@night\" + 0.099*\"mock\" + -0.091*\"position.\" + -0.086*\"classes\" + 0.085*\"technical\" + 0.081*\"interview\" + 0.081*\"interviews\" + -0.078*\"fill\"',\n",
        " '0.326*\"edward\" + -0.262*\"chair\" + 0.141*\"hackathon\" + 0.112*\"google\" + -0.104*\"interview\" + -0.104*\"elections\" + -0.102*\"interviews\" + 0.097*\"april\" + -0.096*\"mock\" + -0.089*\"cos\"',\n",
        " '-0.202*\"interviews\" + -0.187*\"mock\" + -0.186*\"interview\" + -0.168*\"technical\" + -0.165*\"chair\" + 0.152*\"computer\" + 0.151*\"topic\" + 0.112*\"cos\" + -0.103*\"career\" + 0.101*\"table\"']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "messages = [email['message'] for email in emails if email['sender'] == \"David Bieber <dbieber@PRINCETON.EDU>\" ]\n",
      "words = ' '.join(messages).split()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(list(set(words[:35000])))\n",
      "print len(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8034\n",
        "40108\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emails[9]['sender']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "u'David Bieber <dbieber@PRINCETON.EDU>'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=10, iterations=500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda.print_topics(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "['0.011*with + 0.010*from + 0.009*will + 0.008*have + 0.007*that + 0.006*your + 0.006*about + 0.005*all + 0.005*it + 0.005*here',\n",
        " '0.016*will + 0.009*about + 0.008*your + 0.007*that + 0.007*have + 0.007*from + 0.007*with + 0.007*by + 0.006*> + 0.006*more',\n",
        " '0.011*will + 0.010*with + 0.009*have + 0.009*up + 0.009*your + 0.008*from + 0.008*about + 0.007*sign + 0.005*princeton + 0.005*can',\n",
        " '0.010*will + 0.008*from + 0.007*have + 0.006*it + 0.006*about + 0.006*your + 0.006*with + 0.006*that + 0.006*princeton + 0.005*,',\n",
        " '0.010*will + 0.008*with + 0.007*chair + 0.007*your + 0.007*have + 0.006*that + 0.006*princeton + 0.005*by + 0.005*want + 0.004*can',\n",
        " '0.010*from + 0.009*will + 0.008*with + 0.007*about + 0.006*princeton + 0.006*can + 0.005*your + 0.005*out + 0.005*by + 0.005*our',\n",
        " '0.013*will + 0.010*your + 0.010*with + 0.008*have + 0.008*or + 0.007*from + 0.007*that + 0.006*about + 0.005*all + 0.005*cs',\n",
        " '0.011*will + 0.008*programmer + 0.008*all + 0.008*up + 0.007*with + 0.007*sign + 0.007*your + 0.006*programming + 0.006*secondary + 0.006*have',\n",
        " '0.008*princeton + 0.008*that + 0.006*have + 0.006*with + 0.006*your + 0.006*our + 0.006*or + 0.005*who + 0.005*from + 0.005*want',\n",
        " '0.015*will + 0.009*with + 0.008*can + 0.008*your + 0.008*that + 0.008*about + 0.007*have + 0.006*by + 0.006*what + 0.005*all']"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def smallword(w):\n",
      "    return word.lower().replace('[\"#]','')\n",
      "new_words = [smallword(word) for word in words]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'words' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-80c076db1366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmallword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\"#]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msmallword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smallword(\"HEY\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'word' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-bd12cbe8aa16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmallword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-2-80c076db1366>\u001b[0m in \u001b[0;36msmallword\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmallword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\"#]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msmallword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'word' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}